<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>JSDoc: Source: doc/HTML5/embind/VisageFaceAnalyser.js</title>
    
    <script src="scripts/prettify/prettify.js"> </script>
    <script src="scripts/prettify/lang-css.js"> </script>
    <!--[if lt IE 9]>
      <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link type="text/css" rel="stylesheet" href="styles/prettify-tomorrow.css">
    <link type="text/css" rel="stylesheet" href="styles/jsdoc-default.css">
</head>

<body>

<div id="main">
    
    <h1 class="page-title">Source: doc/HTML5/embind/VisageFaceAnalyser.js</h1>
    
    


    
    <section>
        <article>
            <pre class="prettyprint source"><code>
/** VisageFaceAnalyser contains face analysis algorithms capable of estimating gender and emotion from frontal facial images (yaw between -20 and 20 degrees).
* &lt;br/>&lt;br/>
* Following types of analysis can be used:
* &lt;br/>&lt;br/>
* &lt;table>
* &lt;tr>&lt;td width="250">&lt;b>ANALYSIS TYPE&lt;/b>&lt;/td>&lt;td width="200">&lt;b>FUNCTION&lt;/b>&lt;/td>&lt;/tr>
* &lt;tr>&lt;td>age estimation&lt;/td>&lt;td>estimateAge()&lt;/td>&lt;/tr>
* &lt;tr>&lt;td>gender estimation&lt;/td>&lt;td>estimateGender()&lt;/td>&lt;/tr>
* &lt;tr>&lt;td>emotion estimation&lt;/td>&lt;td>estimateEmotion()&lt;/td>&lt;/tr>
* &lt;/table>
* &lt;br/>&lt;br/>
* VisageFaceAnalyser class requires, by default, data files bundled in visageFaceAnalyser.data file and a loader script visageFaceAnalyser.js located in www/lib/ folder. Files for VisageFaceAnalyser are bundled and loaded separately from files bundled for VisageTracker class.
* &lt;br/>&lt;br/>
* &lt;b>For every application using VisageFaceAnalyser API, visageFaceAnalyser.data file and visageFaceAnalyser.js loading script must be copied to the same folder where the application's main html file is located&lt;/b> (e.g. Samples/ShowcaseDemo folder).
* &lt;br/>
* &lt;b>
* Additionally, visageFaceAnalyser.js script must be loaded before the main visageSDK.js script is loaded.
* &lt;/b>
* &lt;br/>&lt;br/>
* For example - loading visageFaceAnalyser.data file:
* &lt;pre class="prettyprint source">&lt;code>
* 
* &lt;script src="visageFaceAnalyser.js">&lt;/script>
* &lt;script src="../../lib/visageSDK.js">&lt;/script>
*
* &lt;/code>&lt;/pre>
* &lt;br/>
* &lt;br/>&lt;br/>
* &lt;b>Changing the location of the .data file&lt;/b>
* &lt;br/>
* Location of the .data file can be changed by overriding the &lt;i>locateFile&lt;/i> attribute of the Module object to return the URL where the data file is currently stored. Note that the new location applies to all visage|SDK data files (visageSDK.data, visageRecognitionData.data and visageAnalyser.data).
* This additional code needs to be added to the application's main html file and the Module' attribute must be specified in a script element before the one that loads the data file (in this case visageFaceAnalyser.js). 
* &lt;br/>&lt;br/>
* Sample usage - changing .data file location:
* &lt;br/>
* &lt;pre class="prettyprint source">&lt;code>
* 
* &lt;script>
* var Module = {
*  'locateFile':  function(dataFileName) {var fullPath = "http://localhost/www.visagetechnologies.com/Samples/" + dataFileName; return fullPath}
* };
* &lt;/script>
* &lt;script src="../../lib/visageFaceAnalyser.js">&lt;/script>
*
* &lt;/code>&lt;/pre>
* &lt;br/>
* &lt;br/>&lt;br/>

* &lt;b>Download complete callback&lt;/b>
* &lt;br/>
* visage|SDK calls a method when all the data has been downloaded from the server and when the tracker is ready to start tracking. 
* To take specific action at that time a method named "callbackDownload" must be implemented in 
* the global scope (e.g in the main application's html file).
* &lt;br/>&lt;br/>
* Sample usage - enabling buttons:
* &lt;br/>
* &lt;pre class="prettyprint source">&lt;code>
* 
* function callbackDownload(){
*	var btnStart = document.getElementById('buttonStart');
*	var btnDraw = document.getElementById('buttonTDraw');
*	btnStart.disabled = false;
*	btnDraw.disabled = false;
* }
*
* &lt;/code>&lt;/pre>
* &lt;br/>&lt;br/>
* @constructor
*/
function VisageFaceAnalyser()
{
	/** 
	* Estimates gender from a facial image.
	* &lt;br/>&lt;br/>
	* The function returns 1 if estimated gender is male and 0 if it is a female. Prior to using this function, it is necessary to process the facial image or video frame using VisageTracker or VisageDetector. 
	* This function estimates gender for last image processed by {@link VisageTracker#track|VisageTracker.track()} or {@link VisageDetector#detectFeatures|VisageDetector.detectFeatures()} function.
	* @param {number} frameWidth - Width of the frame
	* @param {number} frameHeight - Height of the frame
	* @param {number} p_imageData - Pointer to image pixel data, size of the array must correspond to frameWidth and frameHeight
	* @param {number} faceData - FaceData object filled with tracking results from a previous call of the {@link VisageTracker#track|VisageTracker.track()} or 
	* {@link VisageDetector#detectFeatures|VisageDetector.detectFeatures()} function.
	* @returns {number} returns 0 if estimated gender is female, 1 if it is a male and -1 if it failed.
	*/
	this.estimateGender = function(frameWidth, frameHeight, p_imageData, faceData){};

	/** 
	* Estimates emotion from a facial image.
	* &lt;br/>&lt;br/>
	* The function returns estimated probabilities for basic emotions. Prior to using this function, it is necessary to process the facial image or video frame using VisageTracker or VisageDetector. 
	* This function estimates emotions for last image processed by {@link VisageTracker#track|VisageTracker.track()} or {@link VisageDetector#detectFeatures|VisageDetector.detectFeatures()} function.
	* @param {number} frameWidth - Width of the frame
	* @param {number} frameHeight - Height of the frame
	* @param {number} p_imageData - Pointer to image pixel data, size of the array must correspond to frameWidth and frameHeight
	* @param {number} faceData - FaceData object filled with tracking results from a previous call of the {@link VisageTracker#track|VisageTracker.track()} or 
	* {@link VisageDetector#detectFeatures|VisageDetector.detectFeatures()} function.
	* @param {VectorFloat} array of 6 doubles. If successful, the function will fill this array with estimated probabilities for emotions in this order: anger, disgust, fear, happiness, sadness and surprise. 
	* Each probability will have a value between 0 and 1. Sum of probabilities does not have to be 1.
	* @see {@link VectorFloat}
	* @returns {number} returns 1 if estimation was successful or 0 if estimation was unsuccessful.
	*/
	this.estimateEmotion = function(frameWidth, frameHeight, p_imageData, faceData, emotionProbEstimates){}; 


	/** 
	* Estimates age from a facial image.
	* &lt;br/>&lt;br/>
	* The function returns estimated age. Prior to using this function, it is necessary to process the facial image or video frame using VisageTracker. 
	* This function estimates age for for last image processed by {@link VisageTracker#track|VisageTracker.track()} or {@link VisageDetector#detectFeatures|VisageDetector.detectFeatures()} function.
	* @param {number} frameWidth - Width of the frame
	* @param {number} frameHeight - Height of the frame
	* @param {number} p_imageData - Pointer to image pixel data, size of the array must correspond to frameWidth and frameHeight
	* @param {number} faceData - FaceData object filled with tracking results from a previous call of the {@link VisageTracker#track|VisageTracker.track()} or 
	* {@link VisageDetector#detectFeatures|VisageDetector.detectFeatures()} function.
	* @returns {number} returns estimated age if estimation was successful or -1 if it failed.
	*/
	this.estimateAge = function (index){};


	/** Get normalized face image.
	* &lt;br/>&lt;br/>
	* This function returns normalized face image with corresponding feature points.
	* Size of the normalized face in the image is such that inter-pupillary distance is approximately quarter of the image width.
	* &lt;br/>&lt;br/>
	* Face will be normalized to a varying degree depending on normalization type. For example rotated 
	* face with open mouth will only have its pose straightened with normalization type VS_NORM_POSE while
	* with addition of VS_NORM_AU normalized face will also have closed mouth.
	* &lt;br/>&lt;br/>
	* Note that the face will always have its pose straightened.
	* &lt;br/>&lt;br/>
	* Types of normalization are:
	*   - VS_NORM_POSE - face translation and rotation are set to zero thereby normalizing the pose
	*   - VS_NORM_SU - parameters describing the face shape (shape units) are set to zero thereby normalizing the face shape
	*   - VS_NORM_AU - parameters describing facial movements (action units) are set to zero, for example open mouth will be closed
	* &lt;br/>&lt;br/>
	* Different types of normalization can be combined with "|" operator, for example VS_NORM_POSE | VS_NORM_SU.
	* &lt;br/>&lt;br/>
	* @param frame image containing the face to be normalized, must be grey-scale
	* @param normFace image containing the normalized face; it must be allocated before calling the function; face size will depend on this image size
	* @param face_data FaceData structure containing the information about the face that will be normalized
	* @param normFDP features points that correspond to the normalized face; coordinates are normalized to 0-1 range
	* @param norm_type normalization type, a binary combination of VS_NORM_POSE - normalizes pose, VS_NORM_SU - normalizes shape units and VS_NORM_AU - normalizes action units
	* @param dataPath path to the folder where Face Detector.cfg is located, default values is ""
	*/
}</code></pre>
        </article>
    </section>




</div>

<nav>
    <h2><a href="index.html">Index</a></h2><h3>Classes</h3><ul><li><a href="FaceData.html">FaceData</a></li><li><a href="ScreenSpaceGazeData.html">ScreenSpaceGazeData</a></li><li><a href="VectorFloat.html">VectorFloat</a></li><li><a href="VectorInt.html">VectorInt</a></li><li><a href="VectorString.html">VectorString</a></li><li><a href="VisageFaceAnalyser.html">VisageFaceAnalyser</a></li><li><a href="FeaturePoint.html">FeaturePoint</a></li><li><a href="FDP.html">FDP</a></li><li><a href="VisageDetector.html">VisageDetector</a></li><li><a href="FaceDataVector.html">FaceDataVector</a></li><li><a href="VisageGazeTracker.html">VisageGazeTracker</a></li><li><a href="VisageFaceRecognition.html">VisageFaceRecognition</a></li><li><a href="VisageTracker.html">VisageTracker</a></li><li><a href="VisageAR.html">VisageAR</a></li></ul><h3>Global</h3><ul><li><a href="global.html#FP_START_GROUP_INDEX">FP_START_GROUP_INDEX</a></li><li><a href="global.html#FP_END_GROUP_INDEX">FP_END_GROUP_INDEX</a></li><li><a href="global.html#FP_NUMBER_OF_GROUPS">FP_NUMBER_OF_GROUPS</a></li><li><a href="global.html#initializeLicenseManager">initializeLicenseManager</a></li><li><a href="global.html#VisageTrackerStatus">VisageTrackerStatus</a></li><li><a href="global.html#VisageTrackerImageFormat">VisageTrackerImageFormat</a></li></ul>
</nav>

<br clear="both">

<footer>
    Documentation generated by <a href="https://github.com/jsdoc3/jsdoc">JSDoc 3.2.0</a> on Fri Sep 30 2016 17:19:52 GMT+0200 (CEST)
</footer>

<script> prettyPrint(); </script>
<script src="scripts/linenumber.js"> </script>
</body>
</html>
